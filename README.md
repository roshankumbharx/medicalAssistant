# Medical Domain Assistant â€” RAG-Powered Health Information System

A full-stack **Medical Assistant** built using **Retrieval-Augmented Generation (RAG)**. This application allows users to upload medical documents and receive precise, context-aware answers by combining **FastAPI**, **LangChain**, and **Streamlit**.

---

## System Architecture

The application implements a modular RAG pipeline to ensure medical accuracy and data grounding:

1. **Document Ingestion**: Extracts text from medical PDFs using PyMuPDF.
2. **Semantic Chunking**: Breaks text into manageable pieces using RecursiveCharacterTextSplitter.
3. **Vector Embedding**: Generates high-dimensional embeddings via Google gemini-embedding-001.
4. **Vector Storage**: Indexes and stores embeddings in Pinecone DB for low-latency retrieval.
5. **Contextual Retrieval**: Identifies relevant medical segments based on the user's query.
6. **LLM Generation**: Processes the retrieved context through Groq (gpt-oss-120b) to produce factual responses.


---

## Features

* **Intelligent Q&A**: Answers are grounded strictly in the uploaded documents to prevent hallucinations.
* **Real-time Processing**: Fast response times using Groq's high-speed inference.

---

## Tech Stack

| Component | Technology |
| :--- | :--- |
| **LLM** | Groq (openai/gpt-oss-120b) |
| **Embeddings** | Google Generative AI (gemini-embedding-001) |
| **Vector Database** | Pinecone |
| **Orchestration** | LangChain |
| **Backend** | FastAPI |
| **Frontend** | Streamlit |

---

## API Endpoints

### POST /upload_pdfs/
Processes and embeds PDF files into the vector database.

### POST /ask_question/
Retrieves context and generates an answer for a medical query.

---

## Folder Structure
â””â”€â”€ ğŸ“assets
    â”œâ”€â”€ DIABETES.pdf
â””â”€â”€ ğŸ“client
    â””â”€â”€ ğŸ“components
        â”œâ”€â”€ chatUI.py
        â”œâ”€â”€ history_download.py
        â”œâ”€â”€ upload.py
    â””â”€â”€ ğŸ“utils
        â”œâ”€â”€ api.py
    â”œâ”€â”€ app.py
    â”œâ”€â”€ config.py
    â””â”€â”€ requirements.txt
â””â”€â”€ ğŸ“server
    â””â”€â”€ ğŸ“middlewares
        â”œâ”€â”€ exception_handlers.py
    â””â”€â”€ ğŸ“modules
        â”œâ”€â”€ llm.py
        â”œâ”€â”€ load_vectorstore.py
        â”œâ”€â”€ pdf_handlers.py
        â”œâ”€â”€ query_handlers.py
    â””â”€â”€ ğŸ“routes
        â”œâ”€â”€ ask_question.py
        â”œâ”€â”€ upload_pdfs.py
    â””â”€â”€ ğŸ“uploaded_docs
        â”œâ”€â”€ DIABETES.pdf
        â”œâ”€â”€ Supratim Nag - LOR.pdf
    â”œâ”€â”€ .env
    â”œâ”€â”€ logger.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ test.py

---

## Quick Setup
```bash
# Clone the repo
$ git clone https://github.com/roshankumbhar/medicalAssistant.git
$ cd medicalAssistant/server

# Create virtual env
$ uv venv
$ .venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
$ uv pip install -r requirements.txt

# Set environment variables (.env)
GOOGLE_API_KEY=...
GROQ_API_KEY=...
PINECONE_API_KEY=...
PINECONE_INDEX_NAME=...
PINECONE_ENV=...

# Run the server
$ uvicorn main:app --reload --port 8000


$ cd medicalAssistant/client

# Create virtual env
$ uv venv
$ .venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
$ uv pip install -r requirements.txt

# Run the server
$ streamlit run app.py
```

---

## Deployment

Backend Hosted on Render
Frontend Hosted on Streamlit Cloud
